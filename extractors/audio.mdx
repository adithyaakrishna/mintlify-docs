import { Tabs } from 'nextra/components'

# Audio Extractors

#### [ASR Diarization](https://github.com/tensorlakeai/indexify-extractors/tree/main/audio/asrdiarization) ![Static Badge](https://img.shields.io/badge/GPU%20Accelerated-green?logo=nvidia&logoColor=ffffff)
The ASR and diarization pipelines are modularly implemented, with diarization built on ASR outputs. Pyannote is recommended for state-of-the-art diarization. Speculative decoding is added to speed up inference, using a smaller model to suggest generations validated by the larger model. Note that this requires matching decoder architectures and a batch size of 1. For Whisper, a distilled version is suggested as the assistant model.

```bash
indexify-extractor download tensorlake/asrdiarization
```

#### [Whisper](https://github.com/tensorlakeai/indexify-extractors/tree/main/audio/whisper-asr) ![Static Badge](https://img.shields.io/badge/GPU%20Accelerated-green?logo=nvidia&logoColor=ffffff)
This extractor converts extracts transcriptions from audio. The entire text and
chunks with timestamps are represented as metadata of the content.

<Tabs items={['Bash', 'Docker']}>
  <Tabs.Tab>
    ```bash
    indexify-extractor download tensorlake/whisper-asr
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    docker run -d tensorlake/whisper-asr
    ```
  </Tabs.Tab>
</Tabs>
    

#### [Speaker Diarization](https://github.com/tensorlakeai/indexify-extractors/tree/main/audio/whisper-diarization)
This extractor indentifies the speaker for each sentence in the transcription generated by Whisper.

<Tabs items={['Bash', 'Docker']}>
  <Tabs.Tab>
    ```bash
    indexify-extractor download tensorlake/whisper-diarization
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    docker run -d tensorlake/whisper-diarization
    ```
  </Tabs.Tab>
</Tabs>

