---
title: Introduction
---

import { Tabs } from 'nextra/components';

# Effortless Ingestion and Extraction for Unstructured Data at Any Scale

<p align="center">
  ![Indexify High Level](/images/Indexify_KAT.gif)
</p>


Indexify is an open-source data framework. It is designed for creating ingestion and extraction pipelines for unstructured data. The framework uses a declarative approach to perform structured extraction with any AI model or to transform ingested data.

Indexify pipelines operate in real-time. They process data immediately after ingestion. This makes them ideal for interactive applications and low-latency scenarios.

**Use Cases:** Pipelines for Entity Extraction/Embedding from documents, Audio Transcription, Summarization, Object Detection from Images. 

**RAG**: Embedding and structured data extracted by Indexify from enterprise data can be consumed into RAG applications.  

## Multi-Stage Data Ingestion and Extraction Workflows

Extraction Graphs are at the center of Indexify. They are pipelines which processes data and writes the output to databases for retrieval. Extraction policies are linked using the `content_source` attribute. Some unique characteristics of Indexify workflows are -

**AI Native**: Use models from OpenAI, HuggingFace and Ollama in the pipeline.

**Extensible**: by plugging in Python modules in the pipeline.

**Real Time and Scalable**: Handles real-time processing of data at scale powered by a low latency and distributed scheduler.

**APIs**: Pipelines are exposed as HTTP APIs, making them accessible from applications written in TypeScript, Java, Python, Go, etc.

```yaml filename="graph.yaml"
name: 'pdf-ingestion-pipeline'
extraction_policies:
- extractor: 'tensorlake/marker'
  name: 'pdf_to_markdown'
- extractor: 'tensorlake/ner'
  name: 'entity_extractor'
  content_source: 'pdf_to_markdown'
- extractor: 'tensorlake/minilm-l6'
  name: 'embedding'
  content_source: 'pdf_to_markdown'
```

<Tabs items={['cURL', 'Python', 'TypeScript']}>
    <Tabs.Tab>
        ```bash
        curl -X 'POST' \
        'http://localhost:8900/namespaces/default/extraction_graphs' \
        -H 'accept: application/x-yaml' \
        -H 'Content-Type: application/x-yaml' \
        --data-binary @graph.yaml
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```python
        from indexify import IndexifyClient, ExtractionGraph
        graph = ExtractionGraph.from_yaml_file("graph.yaml")
        client = IndexifyClient()
        client.create_extraction_graph(graph)
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```typescript
        ```
    </Tabs.Tab>
</Tabs>
    

### Continuous Data Ingestion

<Tabs items={['cURL', 'Python', 'TypeScript']}>
    <Tabs.Tab>
        ```bash
        curl -X 'POST' \
        'http://localhost:8900/namespaces/default/extraction_graphs/pdf-ingestion-pipeline/extract' \
        -H 'accept: */*' \
        -H 'Content-Type: multipart/form-data' \
        -F 'file=@file.pdf;type=application/pdf' \
        -F 'labels={"source":"arxiv"}'
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```python
        client = IndexifyClient()

        files = ["file1.pdf", .... "file100.pdf"]
        for file in files:
        client.upload_file("pdf-ingestion-pipeline", file)
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```typescript
        ```
    </Tabs.Tab>
</Tabs>

### Retrieve Extracted Data

Retrieve extracted named entities 

<Tabs items={['cURL', 'Python', 'TypeScript']}>
    <Tabs.Tab>
        ```bash
        curl -X 'GET' \
        'http://localhost:8900/namespaces/:namespace/extraction_graphs/pdf-ingestion-pipeline/content/585ebafdbc9dbbbe/extraction_policies/entity_extractor' \
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```python
        content_ids = [content.id for content in client.list_content("pdf-ingestion-pipeline")]

        markdown = client.get_extracted_content(content_ids[0], "pdf-ingestion-pipeline", "pdf_to_markdown")
        named_entities = client.get_extracted_content(content_ids[0], "pdf-ingestion-pipeline", "entity_extractor")
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```typescript
        ```
    </Tabs.Tab>
</Tabs>

Search vector indexes populated by embeddings

<Tabs items={['cURL', 'Python', 'TypeScript']}>
    <Tabs.Tab>
        ```bash
        curl -X 'POST' \
        'http://localhost:8900/namespaces/default/indexes/pdf-ingestion-pipeline.embedding.embedding/search' \
        -H 'accept: application/json' \
        -H 'Content-Type: application/json' \
        -d '{
            "filters": [],
            "include_content": true,
            "k": 3,
            "query": "wework"
        }'
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```python
        results = client.search("pdf-ingestion-pipeline.embedding.embedding","Who won the 2017 NBA finals?", k=3)
        ```
    </Tabs.Tab>
    <Tabs.Tab>
        ```typescript
        ```
    </Tabs.Tab>
</Tabs>

To understand usage of indexify for various use cases we recommend the following starting points.

## Indexify Learning Path 

| Guide | What You'll Build | Key Concepts Covered |
|-------|-------------------|----------------------|
| [Getting Started - Basic](https://docs.getindexify.ai/getting_started/) | A Wikipedia information retrieval system | - Indexify Server setup \n - Extraction Graphs \n - Basic Extractors \n - Data Ingestion \n - Vector Search |
| [Getting Started - Intermediate](https://docs.getindexify.ai/getting_started_intermediate/) | A tax document processing and Q&A system | - PDF processing \n - Custom Extractors \n - Structured Data Extraction \n - Advanced Querying |
| [Multi-Modal RAG on PDF](https://docs.getindexify.ai/example_code/pdf/indexing_and_rag) | A video content analysis and retrieval system | - Multi-modal data processing \n - Video frame extraction \n - Speech-to-text conversion \n - Cross-modal retrieval |


## Why Use Indexify?

Indexify is for continuous ingestion and extraction from unstructured data in a streaming fashion. If you are building LLM Application that need structured data from any unstructured data sources, Indexify is the tool for you.

While there lies a divide in tools for prototyping and for deploying to production, Indexify runs locally on laptops for rapid prototyping, but you can also deploy a scaled up version in production for high availability and reliability.

You should use Indexify if you care about -

* Processing Multi-Modal Data such as PDFs, Videos, Images, and Audio
* High Availability and Fault Tolerance
* Local Experience for rapid prototyping
* Automatically updating indexes whenever upstream data sources are updated
* Incremental Extraction and Selective Deletion
* Compatibility with Various LLM Frameworks (Langchain, DSPy, etc.)
* Integration with any database, blob store or vector store.
* Owning your data infrastructure and being able to deploy on any cloud.
